{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "'/vsizip/./taxi_zones.zip' does not exist in the file system, and is not recognized as a supported dataset name.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mfiona\\\\ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\\\_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: '/vsizip/./taxi_zones.zip' does not exist in the file system, and is not recognized as a supported dataset name.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyathena\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m connect\n\u001b[1;32m---> 10\u001b[0m gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./taxi_zones.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraffic_analysis\u001b[39m(date, borough\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, brand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     14\u001b[0m     year \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(date)\u001b[38;5;241m.\u001b[39myear\n",
      "File \u001b[1;32mc:\\Users\\alosh\\anaconda3\\envs\\tf\\lib\\site-packages\\geopandas\\io\\file.py:297\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_fiona(\n\u001b[0;32m    298\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    299\u001b[0m     )\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\alosh\\anaconda3\\envs\\tf\\lib\\site-packages\\geopandas\\io\\file.py:338\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[1;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m reader(path_or_bytes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[0;32m    339\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alosh\\anaconda3\\envs\\tf\\lib\\site-packages\\fiona\\env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\alosh\\anaconda3\\envs\\tf\\lib\\site-packages\\fiona\\__init__.py:305\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 305\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    306\u001b[0m         path,\n\u001b[0;32m    307\u001b[0m         mode,\n\u001b[0;32m    308\u001b[0m         driver\u001b[38;5;241m=\u001b[39mdriver,\n\u001b[0;32m    309\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    310\u001b[0m         layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[0;32m    311\u001b[0m         enabled_drivers\u001b[38;5;241m=\u001b[39menabled_drivers,\n\u001b[0;32m    312\u001b[0m         allow_unsupported_drivers\u001b[38;5;241m=\u001b[39mallow_unsupported_drivers,\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    314\u001b[0m     )\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    316\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    317\u001b[0m         path,\n\u001b[0;32m    318\u001b[0m         mode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    328\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\alosh\\anaconda3\\envs\\tf\\lib\\site-packages\\fiona\\collection.py:243\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[1;32m--> 243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[1;32mfiona\\\\ogrext.pyx:588\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\\\ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverError\u001b[0m: '/vsizip/./taxi_zones.zip' does not exist in the file system, and is not recognized as a supported dataset name."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import contextily as ctx\n",
    "import geopandas as gpd\n",
    "from pyathena import connect\n",
    "gdf = gpd.read_file(\"./taxi_zones.zip\")\n",
    "\n",
    "def traffic_analysis(date, borough=None, brand=None, n_clusters=3):\n",
    "\n",
    "    year = pd.to_datetime(date).year\n",
    "\n",
    "    conn = connect(aws_access_key_id=AWS_ACCESS_KEY,\n",
    "                   aws_secret_access_key=AWS_SECRET_KEY,\n",
    "                   s3_staging_dir='s3://fireflychick/Results/',\n",
    "                   region_name=AWS_REGION)\n",
    "\n",
    "    def plot(df, date, borough=None, n_clusters=3):\n",
    "\n",
    "        df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "        # df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'])\n",
    "\n",
    "        filtered_df = df[df['pickup_datetime'].dt.date == pd.to_datetime(date).date()]\n",
    "\n",
    "        daily_aggregate_driver_pay = filtered_df['driver_pay'].sum()\n",
    "        daily_aggregate_miles = filtered_df['trip_miles'].sum()\n",
    "        \n",
    "        print(f\"Daily Aggregate Revenue on {date}: ${daily_aggregate_driver_pay:.2f}\")\n",
    "        print(f\"Daily Aggregate Miles Covered on {date}: {daily_aggregate_miles:.2f} miles\")\n",
    "\n",
    "        if borough is None:\n",
    "            fig, ax = plt.subplots(figsize=(20, 20))\n",
    "            gdf.plot(ax=ax, alpha=0.4, edgecolor='k')\n",
    "            ctx.add_basemap(ax, crs=gdf.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "        if borough:\n",
    "            filtered_df = filtered_df[(filtered_df['puborough'] == borough) | (filtered_df['doborough'] == borough)]\n",
    "        \n",
    "        if borough and gdf is not None:\n",
    "            borough_zones = gdf[gdf['borough'] == borough]\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            borough_zones.plot(ax=ax, alpha=0.5, edgecolor='k')\n",
    "            ctx.add_basemap(ax, crs=borough_zones.crs.to_string(), source=ctx.providers.CartoDB.Positron)\n",
    "            ax.set_title(f\"{borough} Taxi Zones\")\n",
    "            plt.show()\n",
    "        \n",
    "        filtered_df['hour'] = filtered_df['pickup_datetime'].dt.hour\n",
    "        hourly_traffic = filtered_df.groupby('hour').size().reset_index(name='trip_counts')\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(data=hourly_traffic, x='hour', y='trip_counts', color='skyblue')\n",
    "        plt.title(f'Hourly Traffic Volume on {date} {\"in \" + borough if borough else \"New York City\"}')\n",
    "        plt.xlabel('Hour of the Day')\n",
    "        plt.ylabel('Number of Trips')\n",
    "        plt.xticks(range(0, 24))\n",
    "        plt.grid(axis='y')\n",
    "        plt.show()\n",
    "        \n",
    "        most_common_pu_zone = filtered_df['puzone'].value_counts().idxmax()\n",
    "        most_common_do_zone = filtered_df['dozone'].value_counts().idxmax()\n",
    "        print(f\"Most common pickup zone: {most_common_pu_zone}\")\n",
    "        print(f\"Most common drop-off zone: {most_common_do_zone}\")\n",
    "\n",
    "        day_name = pd.to_datetime(date).day_name()\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(hourly_traffic[['hour', 'trip_counts']])\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "        kmeans.fit(scaled_features)\n",
    "        hourly_traffic['cluster'] = kmeans.labels_\n",
    "\n",
    "        def format_hour_ampm(hour):\n",
    "\n",
    "            if hour == 0:\n",
    "                return '12 AM'\n",
    "            elif hour < 12:\n",
    "                return f'{hour} AM'\n",
    "            elif hour == 12:\n",
    "                return '12 PM'\n",
    "            else:\n",
    "                return f'{hour - 12} PM'\n",
    "        \n",
    "        hourly_traffic['hour_ampm'] = hourly_traffic['hour'].apply(format_hour_ampm)\n",
    "\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        custom_palette = ['#d62728', '#2ca02c', '#1f77b4']\n",
    "        sns.scatterplot(x='hour_ampm', y='trip_counts', data=hourly_traffic, hue='cluster', palette=custom_palette, s=100)\n",
    "        plt.title(f\"Peak Traffic Clusters on {date} {day_name}\")\n",
    "        plt.xlabel('Time of Day')\n",
    "        plt.ylabel('Number of Trips')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(title='Cluster')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "        for i, center in enumerate(cluster_centers):\n",
    "            print(f\"Cluster {i} on {date} {day_name}: Peak around {format_hour_ampm(int(center[0]))} with {int(center[1])} trips\")\n",
    "\n",
    "    if brand == 'Uber':\n",
    "        table_name = f\"uber_{year}\"\n",
    "    elif brand == 'Lyft':\n",
    "        table_name = f\"lyft_{year}\"\n",
    "    else:\n",
    "        table_name = f\"uber+lyft_{year}\"\n",
    "\n",
    "    conn = connect(aws_access_key_id=AWS_ACCESS_KEY,\n",
    "                   aws_secret_access_key=AWS_SECRET_KEY,\n",
    "                   s3_staging_dir='s3://fireflychick/Results/',\n",
    "                   region_name=AWS_REGION)\n",
    "\n",
    "    query = f\"SELECT * FROM fireflychick.{table_name}\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "\n",
    "    if borough:\n",
    "        df = df[(df['puborough'] == borough) | (df['doborough'] == borough)]\n",
    "\n",
    "    plot(df, date, borough, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date format is YYYY-MM-DD\n",
    "traffic_analysis('2021-12-05','Brooklyn', 'Uber', 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
